# Content #


# Download #
Download Code: [Code](http://lsa-lda.googlecode.com/files/ldaviagibbs.zip)<br>
Download sample model: <a href='http://lsa-lda.googlecode.com/files/model.zip'>Sample</a>
<h1>Compile</h1>
Source code contains two program: lda and topword. lda program do parameter estimation & inference, and topword program outputs the top words of each topic.<br>
1. Compile lda: <br>
<blockquote>$> make clean<br>
$> make<br>
2. Compile topword:<br>
$> make topword<br>
<h1>Parameter estimation</h1>
Command : $> ./lda |topic num| |sample num| |data| |model name|<br>
</blockquote><ul><li>topic num: the number of topics<br>
</li><li>sample num: after gibbs sampling burn in period, we sample |sample num| times and calculate their average value.<br>
</li><li>data: path of the data<br>
</li><li>model name: model's name. output file will be named by |model_name|.|type|<br>
<b>Note that</b> alpha and beta are set as 50/K and 0.1 as default.<br>
<b>e.g.</b> $> ./lda 100 50 ap.data ap<br>
<h1>Top Words of Each Topic</h1>
<blockquote>$> ./topword |phi_file| |vocab_file||out_file|<br>
</blockquote></li><li>phi_file: phi file generated by lda program<br>
</li><li>vocab_file: vocabulary list of the training corpus<br>
</li><li>out_file: output file name<br>
<h1>Input Data Formation</h1>
Input data of this program is the same as blei's C code of LDA <a href='http://www.cs.princeton.edu/~blei/lda-c/'>Here</a><br>
</li><li>|M| |term_1|:|count| |term_2|:|count| ...  |term_N|:|count|<br>
</li><li>|M| is the number of unique terms in the document<br>
</li><li>|count| associated with each term is how many times that term appeared in the document. <br>
<b>Note that</b> |term_1| is an integer which indexes the term; it is not a string.<br>
<h1>Output Data</h1>
Output files contain:<br>
</li><li>|model_name|.theta : estimation for document-topic parameter<br>
</li><li>|model_name|.phi : estimation for topic-word parameter<br>
</li><li>|model_name|.tassgin : topic assigned to each word<br>
</li><li>|model_name|.other : alpha,beta,topic sum,sample sum<br>
<h1>Case Study</h1>
To apply LDA on trn.dat in model.zip:<br>
<h2>Compile LDA</h2>
<blockquote>$> make clean<br>
$> make<br>
$> make topword<br>
<h2>Run LDA</h2>
$> ./lda 100 50 trn.data trn<br>
<h2>Time Consuming, a Comparative Perspectives</h2>
</blockquote></li></ul><blockquote>My computer:<br>
openSUSE 11 <br>
GCC 4.2<br>
Intel Core Duo CPU T2450<br>
2GB RAM<br>
</blockquote><ul><li>ldaviagibbs program: 1000 iterations of burn in period cost 26 minutes and the following 50 sampling cost 14 minutes. memory consuming: 16.8MB<br>
</li><li>Blei's C code: 48 iterations to converge, cost 1h22min, memory consuming: 20.5MB<br>
</li><li>GibbsLDA++: 1000 iterations cost 23min. memory consuming: 17.8MB<br>
<h2>Top Words of Each Topic</h2>
<blockquote>$> topword trn.phi vocab.txt topword<br>
<h1>Data Analysis</h1>
Following lists are parts of the output of the topword program<br>
popular words in topic 1 such as federal, law, government, security etc. are related to policy, so we can name topic 1 as policy.<br>
popular words in topic 2 such as smoking,tobacco, cigarette,ban, health are related to the  issue of smoking, so we can name topic 2 as smoking<br>
popular words in topic 3 such as white house, national, secretary, spokesman are related to government, so we can name topic 3 as government<br>
<table><thead><th> topic 1 </th><th> topic 2 </th><th> topic 3 </th></thead><tbody>
<tr><td>program	 </td><td>report	  </td><td>reagan   </td></tr>
<tr><td>report	  </td><td>commission	</td><td>house    </td></tr>
<tr><td>federal	 </td><td>public	  </td><td>white    </td></tr>
<tr><td>law	     </td><td>smoking	 </td><td>president</td></tr>
<tr><td>programs	</td><td>services	</td><td>administration</td></tr>
<tr><td>government	</td><td>ban	     </td><td>fitzwater</td></tr>
<tr><td>security	</td><td>tobacco	 </td><td>national </td></tr>
<tr><td>national	</td><td>cigarettes	</td><td>secretary</td></tr>
<tr><td>social	  </td><td>product	 </td><td>reagans  </td></tr>
<tr><td>says	    </td><td>health	  </td><td>spokesman</td></tr>
<tr><td>public	  </td><td>sand	    </td><td>first    </td></tr>
<tr><td>money	   </td><td>reynolds	</td><td>office   </td></tr>
<tr><td>system	  </td><td>separate	</td><td>chief    </td></tr>
<tr><td>take	    </td><td>stations	</td><td>presidential</td></tr>
<tr><td>benefits	</td><td>safety	  </td><td>marlin   </td></tr>
<tr><td>private	 </td><td>products	</td><td>security </td></tr>
<tr><td>agencies	</td><td>evidence	</td><td>staff    </td></tr>
<tr><td>make	    </td><td>consumer	</td><td>policy   </td></tr>
<tr><td>agency	  </td><td>rules	   </td><td>made     </td></tr>
<tr><td>act	     </td><td>release	 </td><td>presidents</td></tr>
<tr><td>changes	 </td><td>premier	 </td><td>aides    </td></tr>
<tr><td>violations	</td><td>cigarette	</td><td>adviser  </td></tr>
<tr><td>policy	  </td><td>spokeswoman	</td><td>washington</td></tr>
<tr><td>get	     </td><td>smoke	   </td><td>public   </td></tr>
<tr><td>enforcement	</td><td>taken	   </td><td>word     </td></tr>